---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hello, I am currently pursuing a Ph.D. in computer science at the State Key Laboratory of Internet of Things for Smart City (SKL-IOTSC), University of Macau, under the supervision of Prof. [Jianbing Shen (IEEE Fellow)](https://scholar.google.com/citations?user=_Q3NTToAAAAJ&hl=en). Concurrently, I am working under the guidance of Prof. [Yu Cheng](https://ych133.github.io/) from the Chinese University of Hong Kong. I completed my master's degree from Fudan University, supervised by Prof. [Wenqiang Zhang](http://www.fudanroilab.com/2021/07/01/WenqiangZhang.html). Throughout my academic journey, I have been fortunate to collaborate with Dr. [Xiubo Geng](https://xiubo0211.github.io/) from Microsoft, Prof. [Guodong Long](https://guodonglong.github.io/) from the University of Technology Sydney, and Dr. [Tao Shen](https://scholar.google.com/citations?user=SegyX9AAAAAJ&hl=en) from Oracle.

My research centers on **Large Language Models**, and **Multimodal Models**, supported by the Fundamental Research Project for Young Ph.D. students from NSFC (ÂõΩÂÆ∂Ëá™ÁÑ∂ÁßëÂ≠¶Âü∫ÈáëÈùíÂπ¥Â≠¶ÁîüÂü∫Á°ÄÁ†îÁ©∂È°πÁõÆ(ÂçöÂ£´Áîü)). 
The overarching goal of my work is to advance machine intelligence to serve humanity.
My interests are the understanding, analysis, and improvement of LLMs/MLLMs and their applications in AI Healthcare and Visual Generation. 
I am always open for research discussions and collaborations. If you are interested in discussing or collaborating, please feel free to contact me via email.


<!-- ## News <g-emoji class="g-emoji" alias="memo" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png">üî•</g-emoji> -->
<!-- timetable and other -->





## Selected Preprint <g-emoji class="g-emoji" alias="memo" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4dd.png">üìù</g-emoji>
**Yucheng Zhou**, Jihai Zhang, Guanjie Chen, Jianbing Shen, Yu Cheng. Less Is More: Vision Representation Compression for Efficient Video Generation with Large Language Models. ([pdf](https://openreview.net/pdf?id=S7yRfgmnpm)).

**Yucheng Zhou**, Zhi Rao, Jun Wan, Jianbing Shen. Rethinking Visual Dependency in Long-Context Reasoning for Large Vision-Language Models. ([pdf](https://arxiv.org/pdf/2410.19732?)).

**Yucheng Zhou**, Jiahao Yuan, Qianning Wang. Draw ALL Your Imagine: A Holistic Benchmark and Agent Framework for Complex Instruction-based Image Generation. ([pdf](https://arxiv.org/pdf/2505.24787?), [code](https://github.com/yczhou001/LongBench-T2I)).


## Selected Publications <g-emoji class="g-emoji" alias="memo" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4dd.png">üìú</g-emoji>
Full list on [Google Scholar](https://scholar.google.com/citations?hl=en&user=nnbFqRAAAAAJ)

**Yucheng Zhou**, Jianbing Shen, Yu Cheng. Weak to Strong Generalization for Large Language Models with Multi-capabilities. ICLR 2025 ([pdf](https://openreview.net/forum?id=N1vYivuSKq)).

**Yucheng Zhou**, Lingran Song, Jianbing Shen. MAM: Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via Role-Specialized Collaboration. ACL 2025 ([pdf](https://aclanthology.org/2025.findings-acl.1298.pdf), [code](https://github.com/yczhou001/MAM)).

**Yucheng Zhou**, Lingran Song, Jianbing Shen. Improving Medical Large Vision-Language Models with Abnormal-Aware Feedback. ACL 2025 ([pdf](https://aclanthology.org/2025.acl-long.636.pdf)).

Hongji Yang, **Yucheng Zhou**, Wencheng Han, Jianbing Shen. Self-Rewarding Large Vision-Language Models for Optimizing Prompts in Text-to-Image Generation. ACL 2025 ([pdf](https://aclanthology.org/2025.findings-acl.383.pdf)).

Zesheng Shi, **Yucheng Zhou**, Jing Li, Yuxin Jin, Yu Li, Daojing He, Fangming Liu, Saleh Alharbi, Jun Yu, Min Zhang. Safety Alignment via Constrained Knowledge Unlearning. ACL 2025 ([pdf](https://aclanthology.org/2025.acl-long.1240.pdf)).

Hongji Yang, Wencheng Han, **Yucheng Zhou**, Jianbing Shen. DC-ControlNet: Decoupling Inter-and Intra-Element Conditions in Image Generation with Diffusion Models. ICCV 2025 ([pdf](https://arxiv.org/pdf/2502.14779)).

Guanjie Chen, Xinyu Zhao, **Yucheng Zhou**, Xiaoye Qu, Tianlong Chen, Yu Cheng. Towards Stabilized and Efficient Diffusion Transformers through Long-Skip-Connections with Spectral Constraints. ICCV 2025 ([pdf](https://arxiv.org/pdf/2411.17616), [code](https://github.com/OpenSparseLLMs/Skip-DiT)).

Dubing Chen, Huan Zheng, **Yucheng Zhou**, Xianfei Li, Wenlong Liao, Tao He, Pai Peng, Jianbing Shen. Causality-Driven Vision-Based 3D Semantic Occupancy Prediction. ICCV 2025.

Chenglin Wang, **Yucheng Zhou**, Qianning Wang, Zhe Wang, Kai Zhang. ComplexBench-Edit: Benchmarking Complex Instruction-Driven Image Editing via Compositional Dependencies. ACMMM 2025 ([pdf](https://www.arxiv.org/pdf/2506.12830), [code](https://github.com/llllly26/ComplexBench-Edit)).

Chenglin Wang, **Yucheng Zhou**, Zijie Zhai, Jianbing Shen, Kai Zhang. Alternate Geometric and Semantic Denoising Diffusion for Protein Inverse Folding. ECML 2025 ([pdf](https://arxiv.org/pdf/2412.09380v1)).

Xiang Li, **Yucheng Zhou**, Laiping Zhao, Jing Li, Fangming Liu. Impromptu Cybercrime Euphemism Detection. COLING 2025 ([pdf](https://aclanthology.org/2025.coling-main.612.pdf)).

**Yucheng Zhou**, Xiang Li, Qianning Wang, Jianbing Shen. Visual In-Context Learning for Large Vision-Language Models. ACL 2024 ([pdf](https://aclanthology.org/2024.findings-acl.940.pdf), [code](https://github.com/yczhou001/VICL)).

**Yucheng Zhou**, Tao Shen, Xiubo Geng, Chongyang Tao, Jianbing Shen, Guodong Long, Can Xu, Daxin Jiang. Fine-Grained Distillation for Long Document Retrieval. AAAI 2024 ([pdf](https://arxiv.org/pdf/2212.10423.pdf), [code](https://github.com/yczhou001/FGD)).

Wei Tao, **Yucheng Zhou**, Yanlin Wang, Wenqiang Zhang, Hongyu Zhang, Yu Cheng. MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution. NeurIPS 2024 ([pdf](https://proceedings.neurips.cc/paper_files/paper/2024/file/5d1f02132ef51602adf07000ca5b6138-Paper-Conference.pdf), [code](https://github.com/co-evolve-lab/magis)).

Jiashuo Sun, Jihai Zhang, **Yucheng Zhou**, Zhaochen Su, Xiaoye Qu, Yu Cheng. SURf: Teaching Large Vision-Language Models to Selectively Utilize Retrieved Information. EMNLP 2024 ([pdf](https://aclanthology.org/2024.emnlp-main.434.pdf), [code](https://github.com/gasolsun36/surf)).

Qian Li, **Yucheng Zhou**, Cheng Ji, Feihong Lu, Jianian Gong, Shangguang Wang, Jianxin Li. Multi-Modal Inductive Framework for Text-Video Retrieval. ACMMM 2024 ([pdf](https://dl.acm.org/doi/10.1145/3664647.3681024)).

Wei Tao, **Yucheng Zhou**, Yanlin Wang, Hongyu Zhang, Haofen Wang, Wenqiang Zhang. KADEL: Knowledge-Aware Denoising Learning for Commit Message Generation. ACM TOSEM 2024 ([pdf](https://dl.acm.org/doi/10.1145/3643675)).

**Yucheng Zhou**, Guodong Long. Improving Cross-modal Alignment for Text-Guided Image Inpainting. EACL 2023 ([pdf](https://aclanthology.org/2023.eacl-main.250.pdf)).

**Yucheng Zhou**, Guodong Long. Style-Aware Contrastive Learning for Multi-Style Image Captioning. EACL 2023 ([pdf](https://aclanthology.org/2023.findings-eacl.169.pdf)).

**Yucheng Zhou**, Guodong Long. Multimodal Event Transformer for Image-guided Story Ending Generation. EACL 2023 ([pdf](https://aclanthology.org/2023.eacl-main.249.pdf)).

**Yucheng Zhou**, Tao Shen, Xiubo Geng, Chongyang Tao, Can Xu, Guodong Long, Binxing Jiao, Daxin Jiang. Towards Robust Ranker for Text Retrieval. ACL 2023 ([pdf](https://arxiv.org/pdf/2206.08063.pdf), [code](https://huggingface.co/YCZhou/R2ANKER)).

**Yucheng Zhou**, Tao Shen, Xiubo Geng, Guodong Long, Daxin Jiang. ClarET: Pre-training a Correlation-Aware Context-To-Event Transformer for Event-Centric Generation and Classification. ACL 2022 ([pdf](https://aclanthology.org/2022.acl-long.183.pdf), [code](https://aclanthology.org/2022.acl-long.183/), [data](https://github.com/yczhou001/ClarET)).

**Yucheng Zhou**, Xiubo Geng, Tao Shen, Guodong Long, Daxin Jiang. EventBERT: A Pre-Trained Model for Event Correlation Reasoning. WWW 2022 ([pdf](https://dl.acm.org/doi/abs/10.1145/3485447.3511928), [data](https://github.com/yczhou001/ClarET)).

**Yucheng Zhou**, Xiubo Geng, Tao Shen, Jian Pei, Wenqiang Zhang, Daxin Jiang. Modeling Event-Pair Relations in External Knowledge Graphs for Script Reasoning. ACL 2021 ([pdf](https://aclanthology.org/2021.findings-acl.403.pdf), [data](https://github.com/yczhou001/ClarET)).

**Yucheng Zhou**, Xiubo Geng, Tao Shen, Wenqiang Zhang, Daxin Jiang. Improving Zero-Shot Cross-lingual Transfer for Multilingual Question Answering over Knowledge Graph. NAACL 2021 ([pdf](https://aclanthology.org/2021.naacl-main.465.pdf), [data](https://github.com/yczhou001/Multilingual-KBQA-Dataset)).





## Experiences <g-emoji class="g-emoji" alias="briefcase" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bc.png">üíº</g-emoji>

- 2023 - Present, Research Internship at Shanghai AI Lab
- 2020 - 2023, Research Internship at Microsoft




## Professional Services <g-emoji class="g-emoji" alias="sparkles" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f58a.png?v8">üñä</g-emoji>

- Conference Area Chair / Meta-Reviewer: \
ACL (2025), EMNLP (2025), NeurIPS (2025), KDD (2025-2026), AAAI (2026), IJCAI (2023-2025)

- Conference PC Member / Reviewer: \
ICLR (2025), NeurIPS (2024-2025), ICML (2025), ACL (2022-2024), EMNLP (2022-2024), NAACL (2022,2024-2025), COLM (2025), EACL (2024), CVPR (2025), ICCV (2025), ECCV (2024), KDD (2022-2024), SIGIR (2025), AAAI (2024-2026), ACMMM (2022-2025), WSDM (2026), AISTATS (2023-2025)

- Journal Reviewer: \
IEEE Transactions on Affective Computing, Pattern Recognition, Information Fusion, Neural Networks



<!-- ## Selected Awards <g-emoji class="g-emoji" alias="sparkles" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png">‚ú®</g-emoji> -->


<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=250&t=tt&d=Nnem6cnBKrTWlQflRw_36Uq6Iy-QmEldmoz6Wszl1xY&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script>